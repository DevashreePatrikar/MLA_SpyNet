{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOReFOFkoCla6IftNpantsD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevashreePatrikar/MLA_SpyNet/blob/main/MLA_SpyNet_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YArZ9P_tvGik"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# ---------------------------\n",
        "# Load trained MLA-SpyNet model\n",
        "# ---------------------------\n",
        "mla_model = load_model(\"models/mla_spynet_trained.h5\")\n",
        "\n",
        "# ---------------------------\n",
        "# Load test dataset\n",
        "# ---------------------------\n",
        "def load_test_data(im_dir):\n",
        "    all_images = []\n",
        "    list_of_files = sorted(os.listdir(im_dir))\n",
        "    for im_folder in list_of_files:\n",
        "        list_of_img_files = sorted(os.listdir(os.path.join(im_dir, im_folder)))\n",
        "        for image_file in list_of_img_files:\n",
        "            image_path = os.path.join(im_dir, im_folder, image_file)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.resize(image, (128, 128))\n",
        "            all_images.append([image])\n",
        "    all_images = np.array(all_images).reshape(-1, 20, 128, 128, 1)  # 20 frames per sequence\n",
        "    return all_images\n",
        "\n",
        "test_data = load_test_data(\"/content/drive/MyDrive/Test_Data\")\n",
        "\n",
        "# ---------------------------\n",
        "# Load Bayesian threshold from training\n",
        "# ---------------------------\n",
        "R_th = np.load(\"models/bayesian_threshold.npy\")  # assuming you saved it during training\n",
        "\n",
        "# ---------------------------\n",
        "# Compute End-Point Error (EPE)\n",
        "# ---------------------------\n",
        "def compute_epe(R_L, R_gt):\n",
        "    return np.sqrt(np.sum((R_L - R_gt) ** 2, axis=-1)).mean()\n",
        "\n",
        "# ---------------------------\n",
        "# Run Test\n",
        "# ---------------------------\n",
        "for seq_idx, sequence in enumerate(test_data):\n",
        "    print(f\"Processing sequence {seq_idx + 1}/{len(test_data)}\")\n",
        "    for i in range(sequence.shape[0] - 1):  # avoid index error\n",
        "        Z_n = sequence[i, ..., 0]\n",
        "        Z_n1 = sequence[i+1, ..., 0]\n",
        "\n",
        "        # Predicted optical flow by MLA-SpyNet\n",
        "        R_L = mla_model.predict(np.expand_dims(np.stack([Z_n, Z_n1], axis=-1), axis=0))[0]\n",
        "\n",
        "        # Ground truth: consecutive frames (same as training)\n",
        "        R_gt = np.stack([Z_n, Z_n1], axis=-1)\n",
        "\n",
        "        # Compute EPE\n",
        "        epe = compute_epe(R_L, R_gt)\n",
        "\n",
        "        # Detect anomaly using Bayesian threshold\n",
        "        if epe > R_th:\n",
        "            print(f\"Anomaly detected at frame {i} in sequence {seq_idx + 1}\")\n"
      ]
    }
  ]
}